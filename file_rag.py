import os
import json
from docx import Document
from PyPDF2 import PdfReader
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from ollama import Client
import time
from typing import List, Dict, Any
import re
import requests
import asyncio
from functools import lru_cache
import concurrent.futures
import hashlib
import urllib.parse
import random
import aiohttp


class FileRAGSystem:
    def __init__(self):
        # åˆå§‹åŒ–APIé…ç½®
        self.youdao_appid = "1f5bd96a38c3b8b2"  # ç½‘æ˜“æœ‰é“ç¿»è¯‘APPID
        self.youdao_key = "EwPd4WD9wnhTsBLWZffR5RPXBtLiXWNy"  # ç½‘æ˜“æœ‰é“ç¿»è¯‘å¯†é’¥
        self.zhipu_api_key = "0e9517beeddfa990fa4535cf5a586d51.vexg1jTHVdU2b4I5"  # æ™ºè°±APIå¯†é’¥
        self.zhipu_api_url = "https://open.bigmodel.cn/api/paas/v3/model-api/GLM-4-flash/invoke"
        
        # æ£€æŸ¥APIé…ç½®
        if self.youdao_appid == "YOUR_YOUDAO_APPID" or self.youdao_key == "YOUR_YOUDAO_KEY":
            print("è­¦å‘Šï¼šç½‘æ˜“æœ‰é“ç¿»è¯‘APIæœªé…ç½®ï¼Œè¯·æ³¨å†Œå¹¶è·å–APIå¯†é’¥ï¼š")
            print("1. è®¿é—® https://ai.youdao.com/")
            print("2. æ³¨å†Œå¼€å‘è€…è´¦å·")
            print("3. åˆ›å»ºåº”ç”¨è·å–APPIDå’Œå¯†é’¥")
            print("4. å°†è·å–çš„APPIDå’Œå¯†é’¥å¡«å…¥ä»£ç ä¸­")
        
        if self.zhipu_api_key == "YOUR_ZHIPU_API_KEY":
            print("è­¦å‘Šï¼šæ™ºè°±APIæœªé…ç½®ï¼Œè¯·å…ˆé…ç½®APIå¯†é’¥")
            print("1. è®¿é—® https://open.bigmodel.cn/")
            print("2. æ³¨å†Œå¼€å‘è€…è´¦å·")
            print("3. åˆ›å»ºåº”ç”¨è·å–APIå¯†é’¥")
            print("4. å°†è·å–çš„APIå¯†é’¥å¡«å…¥ä»£ç ä¸­")

        # åˆå§‹åŒ–çŸ¥è¯†åº“
        self.knowledge_base = []
        self.embeddings = None

        # æ–‡ä»¶å¤„ç†é…ç½®
        self.supported_extensions = {
            '.txt': self._process_txt,
            '.docx': self._process_docx,
            '.pdf': self._process_pdf,
            '.json': self._process_json
        }

        # æç¤ºè¯æ¨¡æ¿
        self.prompt_template = """åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š

ä¸Šä¸‹æ–‡ï¼š
{context}

é—®é¢˜ï¼š{question}

è¦æ±‚ï¼š
1. å¦‚æœä¸Šä¸‹æ–‡ç›¸å…³ï¼Œä¼˜å…ˆåŸºäºä¸Šä¸‹æ–‡å›ç­”
2. ä¿æŒä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§
3. é¿å…ç¼–é€ ä¸çŸ¥é“çš„ä¿¡æ¯"""

        # ç¿»è¯‘æç¤ºè¯æ¨¡æ¿
        self.translate_templates = {
            'zh2en': """è¯·å°†ä»¥ä¸‹ä¸­æ–‡æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼Œè¦æ±‚ï¼š

1. ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§ï¼š
   - ä¿æŒåŸæ–‡çš„ä¸“ä¸šæœ¯è¯­å’Œæ¦‚å¿µ
   - ç¡®ä¿æŠ€æœ¯æ€§å†…å®¹çš„å‡†ç¡®ç¿»è¯‘
   - ä¿æŒä¸“ä¸šé¢†åŸŸçš„è¡¨è¾¾ä¹ æƒ¯

2. è¯­ä¹‰ä¸€è‡´æ€§ï¼š
   - ä¿æŒåŸæ–‡çš„æ ¸å¿ƒå«ä¹‰
   - ç¡®ä¿ä¸Šä¸‹æ–‡é€»è¾‘è¿è´¯
   - é¿å…æ­§ä¹‰å’Œè¯¯è§£

3. è¯­è¨€è¡¨è¾¾ï¼š
   - ä½¿ç”¨åœ°é“çš„è‹±æ–‡è¡¨è¾¾
   - ä¿æŒåŸæ–‡çš„è¯­æ°”å’Œé£æ ¼
   - ç¡®ä¿è¯­æ³•æ­£ç¡®ï¼Œè¡¨è¾¾æµç•…

4. æ ¼å¼å’Œç»“æ„ï¼š
   - ä¿æŒåŸæ–‡çš„æ®µè½ç»“æ„
   - ä¿ç•™é‡è¦çš„æ ¼å¼æ ‡è®°
   - ä¿æŒæ ‡ç‚¹ç¬¦å·çš„è§„èŒƒä½¿ç”¨

ä¸­æ–‡æ–‡æœ¬ï¼š
{text}""",

            'en2zh': """è¯·å°†ä»¥ä¸‹è‹±æ–‡æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡ï¼Œè¦æ±‚ï¼š

1. ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§ï¼š
   - å‡†ç¡®ç¿»è¯‘ä¸“ä¸šæœ¯è¯­å’Œæ¦‚å¿µ
   - ä¿æŒæŠ€æœ¯æ€§å†…å®¹çš„ä¸“ä¸šæ€§
   - ç¬¦åˆä¸­æ–‡ä¸“ä¸šé¢†åŸŸçš„è¡¨è¾¾ä¹ æƒ¯

2. è¯­ä¹‰ä¸€è‡´æ€§ï¼š
   - ä¿æŒåŸæ–‡çš„æ ¸å¿ƒå«ä¹‰
   - ç¡®ä¿ä¸Šä¸‹æ–‡é€»è¾‘è¿è´¯
   - é¿å…æ­§ä¹‰å’Œè¯¯è§£

3. è¯­è¨€è¡¨è¾¾ï¼š
   - ä½¿ç”¨åœ°é“çš„ä¸­æ–‡è¡¨è¾¾
   - ä¿æŒåŸæ–‡çš„è¯­æ°”å’Œé£æ ¼
   - ç¡®ä¿è¯­æ³•æ­£ç¡®ï¼Œè¡¨è¾¾æµç•…

4. æ ¼å¼å’Œç»“æ„ï¼š
   - ä¿æŒåŸæ–‡çš„æ®µè½ç»“æ„
   - ä¿ç•™é‡è¦çš„æ ¼å¼æ ‡è®°
   - ä¿æŒæ ‡ç‚¹ç¬¦å·çš„è§„èŒƒä½¿ç”¨

è‹±æ–‡æ–‡æœ¬ï¼š
{text}"""
        }

        # æ–‡æœ¬æ¯”è¾ƒæç¤ºè¯æ¨¡æ¿
        self.compare_template = """è¯·ä¸¥æ ¼åˆ†æä»¥ä¸‹ä¸¤æ®µä¸­æ–‡æ–‡æœ¬çš„è´¨é‡ï¼š

åŸæ–‡ï¼š
{original}

æ¶¦è‰²åï¼š
{translated}

è¯·ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢è¿›è¡Œä¸¥æ ¼åˆ†æï¼š

1. ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§ï¼š
   - ä¸“ä¸šæœ¯è¯­çš„ä½¿ç”¨æ˜¯å¦å‡†ç¡®
   - æŠ€æœ¯æ€§å†…å®¹çš„è¡¨è¾¾æ˜¯å¦ä¸“ä¸š
   - æ˜¯å¦ç¬¦åˆä¸“ä¸šé¢†åŸŸçš„è¡¨è¾¾ä¹ æƒ¯

2. è¯­ä¹‰ä¸€è‡´æ€§ï¼š
   - æ˜¯å¦ä¿æŒäº†åŸæ–‡çš„æ ¸å¿ƒå«ä¹‰
   - æ˜¯å¦å­˜åœ¨è¯­ä¹‰åå·®æˆ–é”™è¯¯
   - æ˜¯å¦æœ‰é‡å¤æˆ–å†—ä½™çš„å†…å®¹

3. è¯­è¨€è¡¨è¾¾ï¼š
   - ç”¨è¯æ˜¯å¦å‡†ç¡®ã€ä¸“ä¸š
   - æ˜¯å¦å­˜åœ¨è¯­æ³•é”™è¯¯
   - æ˜¯å¦ç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯
   - è¡¨è¾¾æ˜¯å¦æµç•…è‡ªç„¶

4. é€»è¾‘è¿è´¯æ€§ï¼š
   - å¥å­ä¹‹é—´çš„é€»è¾‘å…³ç³»æ˜¯å¦åˆç†
   - æ˜¯å¦å­˜åœ¨é€»è¾‘è·³è·ƒæˆ–çŸ›ç›¾
   - æ•´ä½“ç»“æ„æ˜¯å¦æ¸…æ™°

5. æ”¹è¿›å»ºè®®ï¼š
   - å¦‚æœæ¶¦è‰²åçš„æ–‡æœ¬å­˜åœ¨é—®é¢˜ï¼Œè¯·æŒ‡å‡ºå…·ä½“é—®é¢˜
   - å¦‚æœåŸæ–‡æ›´å¥½ï¼Œè¯·è¯´æ˜åŸå› 
   - å¦‚æœæ¶¦è‰²åçš„æ–‡æœ¬æ›´å¥½ï¼Œè¯·è¯´æ˜å…·ä½“æ”¹è¿›ä¹‹å¤„

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œè¦æ±‚ï¼š
1. åˆ†æå¿…é¡»å®¢è§‚ã€ä¸¥è°¨
2. å¯¹æ¯ä¸ªæ–¹é¢éƒ½è¦ç»™å‡ºå…·ä½“åˆ†æ
3. å¦‚æœå‘ç°æ¶¦è‰²åçš„æ–‡æœ¬å­˜åœ¨æ˜æ˜¾é—®é¢˜ï¼ˆå¦‚é‡å¤ã€è¯­ä¹‰é”™è¯¯ç­‰ï¼‰ï¼Œå¿…é¡»æ˜ç¡®æŒ‡å‡º
4. æœ€ç»ˆç»“è®ºå¿…é¡»åŸºäºä»¥ä¸Šåˆ†æå¾—å‡º"""

        # åˆ›å»ºçº¿ç¨‹æ± 
        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=4)

        # ç¼“å­˜é…ç½®
        self.translation_cache = {}
        self.analysis_cache = {}

        # æ¨¡å‹å®ä¾‹
        self._embedding_model = None
        self._ollama_client = None
        self._local_model = "llama3:8b"

    @property
    def embedding_model(self):
        if self._embedding_model is None:
            self._embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        return self._embedding_model

    @property
    def ollama_client(self):
        if self._ollama_client is None:
            self._ollama_client = Client(host='http://localhost:11434')
        return self._ollama_client

    @lru_cache(maxsize=100)
    def _process_txt(self, file_path: str) -> List[Dict[str, str]]:
        """å¤„ç†txtæ–‡ä»¶"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return [{"text": content, "source": os.path.basename(file_path)}]

    @lru_cache(maxsize=100)
    def _process_docx(self, file_path: str) -> List[Dict[str, str]]:
        """å¤„ç†docxæ–‡ä»¶"""
        doc = Document(file_path)
        content = "\n".join([paragraph.text for paragraph in doc.paragraphs])
        return [{"text": content, "source": os.path.basename(file_path)}]

    @lru_cache(maxsize=100)
    def _process_pdf(self, file_path: str) -> List[Dict[str, str]]:
        """å¤„ç†pdfæ–‡ä»¶"""
        reader = PdfReader(file_path)
        content = ""
        for page in reader.pages:
            content += page.extract_text() + "\n"
        return [{"text": content, "source": os.path.basename(file_path)}]

    @lru_cache(maxsize=100)
    def _process_json(self, file_path: str) -> List[Dict[str, str]]:
        """å¤„ç†jsonæ–‡ä»¶"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        if isinstance(data, list):
            return data
        elif isinstance(data, dict):
            return [{"text": str(data), "source": os.path.basename(file_path)}]
        else:
            return [{"text": str(data), "source": os.path.basename(file_path)}]

    def upload_file(self, file_path: str) -> bool:
        """ä¸Šä¼ å¹¶å¤„ç†æ–‡ä»¶"""
        try:
            file_ext = os.path.splitext(file_path)[1].lower()
            if file_ext not in self.supported_extensions:
                print(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
                return False

            # å¤„ç†æ–‡ä»¶
            documents = self.supported_extensions[file_ext](file_path)

            # æ·»åŠ åˆ°çŸ¥è¯†åº“
            self.knowledge_base.extend(documents)

            # å¼‚æ­¥æ›´æ–°å‘é‡
            def update_embeddings():
                texts = [doc["text"] for doc in self.knowledge_base]
                self.embeddings = self.embedding_model.encode(texts)

            # ä½¿ç”¨çº¿ç¨‹æ± å¼‚æ­¥å¤„ç†å‘é‡æ›´æ–°
            self.executor.submit(update_embeddings)

            print(f"âœ… æˆåŠŸä¸Šä¼ æ–‡ä»¶: {os.path.basename(file_path)}")
            print(f"ğŸ“š å½“å‰çŸ¥è¯†åº“æ–‡æ¡£æ•°: {len(self.knowledge_base)}")
            return True

        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            return False

    def save_knowledge_base(self, output_path: str = None):
        """ä¿å­˜çŸ¥è¯†åº“åˆ°JSONæ–‡ä»¶"""
        try:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ–‡ä»¶åï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼
            if output_path is None:
                output_path = f"knowledge_base_{time.strftime('%Y%m%d_%H%M%S')}.json"
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            
            # ä¼˜åŒ–JSONåºåˆ—åŒ–
            def default(obj):
                if isinstance(obj, np.ndarray):
                    return obj.tolist()
                return str(obj)
            
            # ä½¿ç”¨æ›´é«˜æ•ˆçš„JSONåºåˆ—åŒ–æ–¹å¼
            with open(output_path, 'w', encoding='utf-8') as f:
                # ä½¿ç”¨separatorså‚æ•°å‡å°‘æ–‡ä»¶å¤§å°
                json.dump(
                    self.knowledge_base, 
                    f, 
                    ensure_ascii=False, 
                    indent=None,  # ç§»é™¤ç¼©è¿›ä»¥å‡å°æ–‡ä»¶å¤§å°
                    separators=(',', ':'),  # ä½¿ç”¨æœ€å°åˆ†éš”ç¬¦
                    default=default
                )
            
            print(f"âœ… çŸ¥è¯†åº“å·²ä¿å­˜åˆ°: {output_path}")
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜çŸ¥è¯†åº“æ—¶å‡ºé”™: {str(e)}")
            return False

    def retrieve(self, query: str, top_k: int = 3) -> List[str]:
        """æ£€ç´¢æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µ"""
        if not self.knowledge_base:
            return []

        query_embedding = self.embedding_model.encode([query])
        similarities = cosine_similarity(query_embedding, self.embeddings)[0]
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        return [self.knowledge_base[i]["text"] for i in top_indices]

    def ask(self, question: str) -> str:
        """åŸºäºçŸ¥è¯†åº“å›ç­”é—®é¢˜"""
        if not self.knowledge_base:
            return "çŸ¥è¯†åº“ä¸ºç©ºï¼Œè¯·å…ˆä¸Šä¼ æ–‡ä»¶ã€‚"

        try:
            contexts = self.retrieve(question)
            prompt = self.prompt_template.format(
                context="\n\n".join(contexts),
                question=question
            )

            response = self.ollama_client.generate(
                model=self._local_model,
                prompt=prompt,
                stream=False,
                options={'temperature': 0.3}
            )
            return response['response'].strip()
        except Exception as e:
            return f"å›ç­”é—®é¢˜æ—¶å‡ºé”™: {str(e)}"

    async def translate_with_youdao(self, text: str, from_lang: str = 'zh-CHS', to_lang: str = 'en') -> str:
        """ä½¿ç”¨ç½‘æ˜“æœ‰é“ç¿»è¯‘APIè¿›è¡Œç¿»è¯‘"""
        if self.youdao_appid == "YOUR_YOUDAO_APPID" or self.youdao_key == "YOUR_YOUDAO_KEY":
            return "é”™è¯¯ï¼šç½‘æ˜“æœ‰é“ç¿»è¯‘APIæœªé…ç½®ï¼Œè¯·å…ˆé…ç½®APIå¯†é’¥"
        
        cache_key = f"youdao_{from_lang}_{to_lang}_{hash(text)}"
        if cache_key in self.translation_cache:
            return self.translation_cache[cache_key]
        
        try:
            salt = str(random.randint(32768, 65536))
            sign = self.youdao_appid + text + salt + self.youdao_key
            sign = hashlib.md5(sign.encode()).hexdigest()
            
            data = {
                'q': text,
                'from': from_lang,
                'to': to_lang,
                'appKey': self.youdao_appid,
                'salt': salt,
                'sign': sign
            }
            
            # è®¾ç½®è¶…æ—¶æ—¶é—´
            timeout = aiohttp.ClientTimeout(total=30)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.post('https://openapi.youdao.com/api', data=data) as response:
                    if response.status != 200:
                        return f"æœ‰é“ç¿»è¯‘APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status}"
                    
                    result = await response.json()
                    if 'translation' in result:
                        translated_text = result['translation'][0]
                        self.translation_cache[cache_key] = translated_text
                        return translated_text
                    else:
                        error_msg = result.get('errorCode', 'æœªçŸ¥é”™è¯¯')
                        return f"æœ‰é“ç¿»è¯‘é”™è¯¯: {error_msg}ï¼Œè¯·æ£€æŸ¥APIé…ç½®æ˜¯å¦æ­£ç¡®"
                    
        except asyncio.TimeoutError:
            return "æœ‰é“ç¿»è¯‘è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
        except aiohttp.ClientError as e:
            return f"æœ‰é“ç¿»è¯‘ç½‘ç»œé”™è¯¯: {str(e)}"
        except Exception as e:
            return f"æœ‰é“ç¿»è¯‘å¤„ç†é”™è¯¯: {str(e)}"

    async def translate_with_zhipu(self, text: str, from_lang: str = 'zh', to_lang: str = 'en', context_prompt: str = '') -> str:
        """ä½¿ç”¨æ™ºè°±APIè¿›è¡Œç¿»è¯‘"""
        if not self.zhipu_api_key:
            return "é”™è¯¯ï¼šæ™ºè°±APIæœªé…ç½®ï¼Œè¯·å…ˆé…ç½®APIå¯†é’¥"
        
        cache_key = f"zhipu_{from_lang}_{to_lang}_{hash(text)}"
        if cache_key in self.translation_cache:
            return self.translation_cache[cache_key]
        
        try:
            headers = {
                "Authorization": f"Bearer {self.zhipu_api_key}",
                "Content-Type": "application/json"
            }
            
            # æ„å»ºç¿»è¯‘æç¤ºè¯
            if from_lang == 'zh' and to_lang == 'en':
                prompt = f"{context_prompt}è¯·å°†ä»¥ä¸‹ä¸­æ–‡æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼Œä¿æŒä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§ï¼š\n\n{text}"
            else:
                prompt = f"{context_prompt}è¯·å°†ä»¥ä¸‹è‹±æ–‡æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡ï¼Œä¿æŒä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§ï¼š\n\n{text}"
            
            data = {
                "prompt": prompt,
                "temperature": 0.3,
                "max_tokens": 2000
            }
            
            response = await asyncio.get_event_loop().run_in_executor(
                self.executor,
                lambda: requests.post(self.zhipu_api_url, headers=headers, json=data)
            )
            
            if response.status_code != 200:
                return f"æ™ºè°±APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
            
            result = response.json()
            if 'data' in result and 'choices' in result['data']:
                translated_text = result['data']['choices'][0]['content'].strip()
                self.translation_cache[cache_key] = translated_text
                return translated_text
            else:
                error_msg = result.get('msg', 'æœªçŸ¥é”™è¯¯')
                return f"æ™ºè°±APIé”™è¯¯: {error_msg}"
        except Exception as e:
            return f"æ™ºè°±APIè°ƒç”¨é”™è¯¯: {str(e)}"

    async def mirror_polish(self, text: str, model: str = 'both', context: str = '') -> Dict[str, Any]:
        """é•œå¼æ¶¦è‰²ï¼šä¸­->è‹±->ä¸­ï¼Œå¹¶æ¯”è¾ƒç»“æœ"""
        result = {
            'original': text,
            'intermediate': {},
            'final': {},
            'comparison': {}
        }

        # æ„å»ºå¸¦æœ‰ä¸Šä¸‹æ–‡çš„æç¤ºè¯
        context_prompt = f"""è¯·å‚è€ƒä»¥ä¸‹ç›¸å…³æ–‡æœ¬è¿›è¡Œç¿»è¯‘ï¼š

ç›¸å…³æ–‡æœ¬ï¼š
{context}

è¦æ±‚ï¼š
1. ä¿æŒä¸“ä¸šæœ¯è¯­çš„ä¸€è‡´æ€§
2. å‚è€ƒç›¸å…³æ–‡æœ¬çš„è¡¨è¾¾æ–¹å¼
3. ç¡®ä¿ç¿»è¯‘çš„å‡†ç¡®æ€§å’Œä¸“ä¸šæ€§

"""

        # å¹¶è¡Œå¤„ç†ç¿»è¯‘ä»»åŠ¡
        tasks = []
        if model in ['youdao', 'both']:
            # ä½¿ç”¨æœ‰é“ç¿»è¯‘
            tasks.append(self.translate_with_youdao(text, 'zh-CHS', 'en'))
        if model in ['zhipu', 'both']:
            # ä½¿ç”¨æ™ºè°±ç¿»è¯‘
            tasks.append(self.translate_with_zhipu(text, 'zh', 'en', context_prompt))

        # ç­‰å¾…æ‰€æœ‰ç¿»è¯‘ä»»åŠ¡å®Œæˆ
        translations = await asyncio.gather(*tasks)

        # å¤„ç†ç¿»è¯‘ç»“æœ
        if model in ['youdao', 'both']:
            result['intermediate']['youdao'] = translations[0]
            # å°†è‹±æ–‡ç¿»è¯‘å›ä¸­æ–‡
            result['final']['youdao'] = await self.translate_with_youdao(translations[0], 'en', 'zh-CHS')
            # åˆ†ææ¶¦è‰²ç»“æœ
            result['comparison']['youdao'] = await self.analyze_text(text, result['final']['youdao'], context)

        if model in ['zhipu', 'both']:
            idx = 1 if model == 'both' else 0
            result['intermediate']['zhipu'] = translations[idx]
            # å°†è‹±æ–‡ç¿»è¯‘å›ä¸­æ–‡
            result['final']['zhipu'] = await self.translate_with_zhipu(translations[idx], 'en', 'zh', context_prompt)
            # åˆ†ææ¶¦è‰²ç»“æœ
            result['comparison']['zhipu'] = await self.analyze_text(text, result['final']['zhipu'], context)

        return result

    async def analyze_text(self, original: str, translated: str, context: str = '') -> Dict[str, Any]:
        """ä½¿ç”¨æ™ºè°±APIåˆ†ææ–‡æœ¬è´¨é‡"""
        try:
            headers = {
                "Authorization": f"Bearer {self.zhipu_api_key}",
                "Content-Type": "application/json"
            }
            
            context_prompt = f"""è¯·å‚è€ƒä»¥ä¸‹ç›¸å…³æ–‡æœ¬è¿›è¡Œåˆ†æï¼š

ç›¸å…³æ–‡æœ¬ï¼š
{context}

"""
            
            prompt = f"""{context_prompt}è¯·ä¸¥æ ¼åˆ†æä»¥ä¸‹ä¸¤æ®µä¸­æ–‡æ–‡æœ¬çš„è´¨é‡ï¼š

åŸæ–‡ï¼š
{original}

æ¶¦è‰²åï¼š
{translated}

è¯·ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢è¿›è¡Œä¸¥æ ¼åˆ†æï¼š

1. ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§ï¼š
   - ä¸“ä¸šæœ¯è¯­çš„ä½¿ç”¨æ˜¯å¦å‡†ç¡®
   - æŠ€æœ¯æ€§å†…å®¹çš„è¡¨è¾¾æ˜¯å¦ä¸“ä¸š
   - æ˜¯å¦ç¬¦åˆä¸“ä¸šé¢†åŸŸçš„è¡¨è¾¾ä¹ æƒ¯
   - æ˜¯å¦ä¸ç›¸å…³æ–‡æœ¬ä¿æŒä¸€è‡´

2. è¯­ä¹‰ä¸€è‡´æ€§ï¼š
   - æ˜¯å¦ä¿æŒäº†åŸæ–‡çš„æ ¸å¿ƒå«ä¹‰
   - æ˜¯å¦å­˜åœ¨è¯­ä¹‰åå·®æˆ–é”™è¯¯
   - æ˜¯å¦æœ‰é‡å¤æˆ–å†—ä½™çš„å†…å®¹
   - æ˜¯å¦ä¸ç›¸å…³æ–‡æœ¬çš„è¯­ä¹‰ä¸€è‡´

3. è¯­è¨€è¡¨è¾¾ï¼š
   - ç”¨è¯æ˜¯å¦å‡†ç¡®ã€ä¸“ä¸š
   - æ˜¯å¦å­˜åœ¨è¯­æ³•é”™è¯¯
   - æ˜¯å¦ç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯
   - è¡¨è¾¾æ˜¯å¦æµç•…è‡ªç„¶

4. é€»è¾‘è¿è´¯æ€§ï¼š
   - å¥å­ä¹‹é—´çš„é€»è¾‘å…³ç³»æ˜¯å¦åˆç†
   - æ˜¯å¦å­˜åœ¨é€»è¾‘è·³è·ƒæˆ–çŸ›ç›¾
   - æ•´ä½“ç»“æ„æ˜¯å¦æ¸…æ™°
   - æ˜¯å¦ä¸ç›¸å…³æ–‡æœ¬çš„é€»è¾‘ä¸€è‡´

5. æ”¹è¿›å»ºè®®ï¼š
   - å¦‚æœæ¶¦è‰²åçš„æ–‡æœ¬å­˜åœ¨é—®é¢˜ï¼Œè¯·æŒ‡å‡ºå…·ä½“é—®é¢˜
   - å¦‚æœåŸæ–‡æ›´å¥½ï¼Œè¯·è¯´æ˜åŸå› 
   - å¦‚æœæ¶¦è‰²åçš„æ–‡æœ¬æ›´å¥½ï¼Œè¯·è¯´æ˜å…·ä½“æ”¹è¿›ä¹‹å¤„
   - å‚è€ƒç›¸å…³æ–‡æœ¬ï¼Œæå‡ºæ›´ä¸“ä¸šçš„æ”¹è¿›å»ºè®®

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œè¦æ±‚ï¼š
1. åˆ†æå¿…é¡»å®¢è§‚ã€ä¸¥è°¨
2. å¯¹æ¯ä¸ªæ–¹é¢éƒ½è¦ç»™å‡ºå…·ä½“åˆ†æ
3. å¦‚æœå‘ç°æ¶¦è‰²åçš„æ–‡æœ¬å­˜åœ¨æ˜æ˜¾é—®é¢˜ï¼ˆå¦‚é‡å¤ã€è¯­ä¹‰é”™è¯¯ç­‰ï¼‰ï¼Œå¿…é¡»æ˜ç¡®æŒ‡å‡º
4. æœ€ç»ˆç»“è®ºå¿…é¡»åŸºäºä»¥ä¸Šåˆ†æå¾—å‡º"""
            
            data = {
                "prompt": prompt,
                "temperature": 0.3,
                "max_tokens": 2000
            }
            
            response = await asyncio.get_event_loop().run_in_executor(
                self.executor,
                lambda: requests.post(self.zhipu_api_url, headers=headers, json=data)
            )
            
            if response.status_code != 200:
                return {
                    'analysis': f"åˆ†æè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}",
                    'better_version': 'original',
                    'suggested_text': original
                }
            
            result = response.json()
            if 'data' in result and 'choices' in result['data']:
                analysis = result['data']['choices'][0]['content'].strip()
                better_version = 'translated' if (
                    'æ¶¦è‰²åçš„æ–‡æœ¬æ›´å¥½' in analysis and 
                    'ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§' in analysis and 
                    'è¯­ä¹‰ä¸€è‡´æ€§' in analysis and 
                    'è¯­è¨€è¡¨è¾¾' in analysis and
                    'é€»è¾‘è¿è´¯æ€§' in analysis and
                    'æ²¡æœ‰å‘ç°æ˜æ˜¾é—®é¢˜' in analysis
                ) else 'original'
                return {
                    'analysis': analysis,
                    'better_version': better_version,
                    'suggested_text': translated if better_version == 'translated' else original
                }
            else:
                return {
                    'analysis': f"åˆ†æå¤±è´¥ï¼š{result.get('msg', 'æœªçŸ¥é”™è¯¯')}",
                    'better_version': 'original',
                    'suggested_text': original
                }
        except Exception as e:
            return {
                'analysis': f"åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}",
                'better_version': 'original',
                'suggested_text': original
            }

    async def polish_text(self, text: str, model: str = 'both') -> Dict[str, Any]:
        """æ¶¦è‰²æ–‡æœ¬ï¼Œå¯é€‰æ‹©ä½¿ç”¨å•ä¸ªæ¨¡å‹æˆ–ä¸¤ä¸ªæ¨¡å‹"""
        try:
            # è®¾ç½®è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            timeout = 60
            
            # ä½¿ç”¨RAGæ£€ç´¢ç›¸å…³æ–‡æœ¬
            if self.knowledge_base:
                related_texts = self.retrieve(text, top_k=3)
                context = "\n\n".join(related_texts)
            else:
                context = ""

            # ä½¿ç”¨asyncio.wait_foræ·»åŠ è¶…æ—¶æ§åˆ¶
            result = await asyncio.wait_for(
                self.mirror_polish(text, model, context),
                timeout=timeout
            )
            
            final_result = {
                'original': text,
                'suggested': {},
                'analysis': {}
            }
            
            if 'youdao' in result['final']:
                final_result['suggested']['youdao'] = result['final']['youdao']
                final_result['analysis']['youdao'] = result['comparison']['youdao']['analysis']
            
            if 'zhipu' in result['final']:
                final_result['suggested']['zhipu'] = result['final']['zhipu']
                final_result['analysis']['zhipu'] = result['comparison']['zhipu']['analysis']
            
            return final_result
            
        except asyncio.TimeoutError:
            print("âŒ æ¶¦è‰²æ“ä½œè¶…æ—¶")
            return {
                'original': text,
                'suggested': {},
                'analysis': {},
                'error': 'æ¶¦è‰²æ“ä½œè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•'
            }
        except Exception as e:
            print(f"âŒ æ¶¦è‰²è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            return {
                'original': text,
                'suggested': {},
                'analysis': {},
                'error': f'æ¶¦è‰²è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}'
            }


def main():
    rag_system = FileRAGSystem()

    print("ğŸ“š RAGæ–‡ä»¶é—®ç­”ç³»ç»Ÿ")
    print("=" * 50)
    print("æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: .txt, .docx, .pdf, .json")
    print("è¾“å…¥ 'exit' é€€å‡º")
    print("è¾“å…¥ 'save' ä¿å­˜çŸ¥è¯†åº“")
    print("è¾“å…¥ 'list' æŸ¥çœ‹å·²ä¸Šä¼ æ–‡ä»¶")
    print("=" * 50)

    while True:
        command = input("\nè¯·è¾“å…¥æ–‡ä»¶è·¯å¾„æˆ–å‘½ä»¤ï¼š")

        if command.lower() in ['exit', 'quit']:
            break

        elif command.lower() == 'save':
            filename = input("è¯·è¾“å…¥ä¿å­˜æ–‡ä»¶åï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤åç§°ï¼‰ï¼š")
            rag_system.save_knowledge_base(filename if filename.strip() else None)

        elif command.lower() == 'list':
            if not rag_system.knowledge_base:
                print("ğŸ“ çŸ¥è¯†åº“ä¸ºç©º")
            else:
                print("\nğŸ“š å·²ä¸Šä¼ æ–‡ä»¶ï¼š")
                for doc in rag_system.knowledge_base:
                    print(f"- {doc['source']}")

        elif os.path.isfile(command):
            rag_system.upload_file(command)

        else:
            print("âŒ æ— æ•ˆçš„å‘½ä»¤æˆ–æ–‡ä»¶è·¯å¾„")

    # é€€å‡ºå‰ä¿å­˜çŸ¥è¯†åº“
    if rag_system.knowledge_base:
        save = input("\næ˜¯å¦ä¿å­˜çŸ¥è¯†åº“ï¼Ÿ(y/n): ")
        if save.lower() == 'y':
            rag_system.save_knowledge_base()


if __name__ == '__main__':
    main()
